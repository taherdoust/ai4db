# Secure API Key Setup for AI4DB

## 🔒 Security First

This guide shows you how to use OpenRouter API securely without exposing your API key in the GitHub repository.

---

## 📋 Quick Setup (3 Steps)

### **Step 1: Get Your API Key**

1. Go to https://openrouter.ai/
2. Sign up or log in
3. Navigate to "Keys" section
4. Create a new API key
5. Copy the key (starts with `sk-or-v1-...`)

### **Step 2: Set Up .env File (Recommended)**

```bash
# Navigate to project directory
cd ~/Desktop/ai4db

# Copy the example file
cp .env.example .env

# Edit .env file and add your actual API key
nano .env
```

In the `.env` file, replace `sk-or-v1-your-key-here` with your actual key:

```bash
# AI4DB Configuration File
OPENROUTER_API_KEY=sk-or-v1-YOUR-ACTUAL-KEY-HERE
OPENROUTER_MODEL=openai/gpt-4-turbo-preview
```

**Save and exit** (Ctrl+X, then Y, then Enter in nano)

### **Step 3: Verify .env is Protected**

```bash
# Check that .env is in .gitignore
cat .gitignore | grep ".env"

# Should show:
# .env
# .env.local
```

✅ Your API key is now secure and won't be committed to GitHub!

---

## 🚀 Alternative Methods

### **Method 1: Environment Variable (Temporary)**

```bash
# Set for current session only
export OPENROUTER_API_KEY="sk-or-v1-YOUR-KEY"

# Run your pipeline
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py --multiplier 8
```

**Note:** This is temporary and will be lost when you close the terminal.

### **Method 2: Add to .bashrc (Permanent)**

```bash
# Edit .bashrc
nano ~/.bashrc

# Add at the end:
export OPENROUTER_API_KEY="sk-or-v1-YOUR-KEY"

# Save and reload
source ~/.bashrc
```

⚠️ **Warning:** This exposes the key in your .bashrc file. Use .env method instead.

---

## 🎯 Using the Enhanced Pipeline

### **With .env File (Recommended)**

```bash
cd ~/Desktop/ai4db

# Install python-dotenv if not already installed
pip install python-dotenv

# Run the enhanced pipeline (automatically loads .env)
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py --multiplier 8
```

### **With Environment Variable**

```bash
export OPENROUTER_API_KEY="sk-or-v1-YOUR-KEY"
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py --multiplier 8
```

### **Command Line Options**

```bash
# Change model (e.g., use Claude 3 Haiku for lower cost)
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py \
  --multiplier 8 \
  --model "anthropic/claude-3-haiku"

# Higher multiplier for more variations
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py \
  --multiplier 10 \
  --model "openai/gpt-4-turbo-preview"
```

---

## 🔍 Verifying Your Setup

### **Check if API Key is Loaded**

```bash
# Test the pipeline (it will show if API key is found)
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py
```

You should see:
```
✓ API key loaded from environment (sk-or-v1-...xxxx)
✓ OpenRouter available with model: openai/gpt-4-turbo-preview
```

### **Check .gitignore Protection**

```bash
# Try to add .env to git (should be ignored)
git status

# Should NOT show .env in untracked files
```

---

## 📊 Model Options & Costs

| Model | Quality | Cost (400K samples) | Best For |
|-------|---------|---------------------|----------|
| `openai/gpt-4-turbo-preview` | 85-88% | $10-30 | **Best quality** |
| `anthropic/claude-3-haiku` | 80-85% | $5-10 | **Budget option** |
| `meta-llama/llama-3-70b-instruct` | 75-80% | $2-5 | **Minimal budget** |

---

## 🆕 What's New in Enhanced Pipeline?

The enhanced pipeline (`stage3_augmentation_pipeline_eclab_openrouter_enhanced.py`) generates **BOTH** natural language questions AND instructions in a single API call:

### **Before (Original Pipeline):**
```json
{
  "question": "Find all buildings within 500m of grid buses",
  "instruction": "Convert this natural language question to PostGIS spatial SQL..."  // Generic placeholder
}
```

### **After (Enhanced Pipeline):**
```json
{
  "question": "Find all buildings within 500m of grid buses in Milan smart district",
  "instruction": "Write a PostGIS SQL query to identify all buildings located within a 500-meter buffer of grid bus stations"  // Specific, contextual instruction
}
```

### **Benefits:**
- ✅ **Cost-efficient**: One API call instead of two (50% cost savings)
- ✅ **Better coherence**: Question and instruction are contextually aligned
- ✅ **Faster**: Half the API calls = half the time
- ✅ **Higher quality**: Both generated by GPT-4 with full context

---

## 🛡️ Security Best Practices

### **DO:**
✅ Use `.env` file for API keys
✅ Keep `.env` in `.gitignore`
✅ Use `.env.example` as a template (without real keys)
✅ Use `python-dotenv` library to load `.env` automatically

### **DON'T:**
❌ Hardcode API keys in Python files
❌ Commit `.env` to GitHub
❌ Share your API key in chat/email
❌ Use the same key for multiple projects (create separate keys)

---

## 🐛 Troubleshooting

### **Problem: API key not found**

```bash
⚠️  API key not found. Please set OPENROUTER_API_KEY
```

**Solution:**
1. Check if `.env` file exists: `ls -la .env`
2. Check if `python-dotenv` is installed: `pip install python-dotenv`
3. Or use environment variable: `export OPENROUTER_API_KEY="your-key"`

### **Problem: .env file not loading**

**Solution:**
```bash
# Install python-dotenv
pip install python-dotenv

# Verify installation
python -c "from dotenv import load_dotenv; print('✓ python-dotenv installed')"
```

### **Problem: API key in git status**

```bash
# If .env shows up in git status
git rm --cached .env
git add .gitignore
git commit -m "Protect API keys"
```

---

## 📖 Complete Example

### **Full Workflow (from scratch):**

```bash
# 1. Navigate to project
cd ~/Desktop/ai4db

# 2. Copy .env template
cp .env.example .env

# 3. Edit .env and add your API key
nano .env
# Add: OPENROUTER_API_KEY=sk-or-v1-YOUR-ACTUAL-KEY

# 4. Install dependencies
pip install python-dotenv sentence-transformers

# 5. Run Stage 1 + 2
python stage1_enhanced_generator_stratified.py 200 100
python stage2_sdv_pipeline_eclab_ctgan.py 50000 300

# 6. Run Enhanced Stage 3 (generates questions + instructions)
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py --multiplier 8

# 7. Check output
ls -lh training_datasets/stage3_augmented_dataset_eclab_openrouter_enhanced.jsonl
```

---

## 💾 Checkpoint & Resume Functionality

The enhanced pipeline now includes **automatic checkpointing**:

### **How It Works:**

- ✅ Saves progress every 1,000 samples automatically
- ✅ Creates two checkpoint files:
  - `stage3_augmented_dataset_eclab_openrouter_enhanced_checkpoint.jsonl` (data)
  - `stage3_augmented_dataset_eclab_openrouter_enhanced_checkpoint_meta.json` (metadata)
- ✅ If interrupted (Ctrl+C, crash, network issue), simply **rerun the same command**
- ✅ Automatically resumes from last checkpoint
- ✅ Cleans up checkpoint files on successful completion

### **Example:**

```bash
# Start pipeline
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py --multiplier 10

# [Process interrupted at sample 5,000/50,000]
# Press Ctrl+C or power failure

# Resume automatically by rerunning the same command
python stage3_augmentation_pipeline_eclab_openrouter_enhanced.py --multiplier 10

# Output:
# [CHECKPOINT] Found existing checkpoint, resuming...
# ✓ Loaded 40,000 samples from checkpoint
# ✓ Resuming from sample 5,001 of 50,000
```

### **Benefits:**

- 🔒 **No data loss**: All processed samples are saved
- ⚡ **Fast recovery**: Resume in seconds, not hours
- 💰 **Cost savings**: Don't pay for duplicate API calls
- 🎯 **Peace of mind**: Can stop/start anytime

---

## 🎉 Summary

- **Secure**: API keys protected by `.gitignore`
- **Flexible**: Use `.env` file or environment variables
- **Enhanced**: Generates both questions AND instructions
- **Cost-effective**: One API call for both (50% savings)
- **Easy**: Simple 3-step setup
- **💾 NEW: Checkpoint/Resume**: Never lose progress if interrupted

**You're now ready to generate high-quality training data securely!** 🚀

